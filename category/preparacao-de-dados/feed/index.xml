<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Preparação de Dados &#8211; R Mining</title>
	<atom:link href="./index.html" rel="self" type="application/rss+xml" />
	<link>./../../../index.html</link>
	<description>Mineração de Dados, Estatística, Tecnologia</description>
	<lastBuildDate>Tue, 17 Jan 2017 10:04:59 +0000</lastBuildDate>
	<language>pt-BR</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.7.1</generator>
	<item>
		<title>RECONHECIMENTO DE DÍGITOS ESCRITOS A MÃO – PARTE 3</title>
		<link>./../../../2016/03/14/reconhecimento-de-digitos-escritos-mao-parte-3/index.html</link>
		<comments>./../../../2016/03/14/reconhecimento-de-digitos-escritos-mao-parte-3/index.html#comments</comments>
		<pubDate>Tue, 15 Mar 2016 02:54:32 +0000</pubDate>
		<dc:creator><![CDATA[Flavio Barros]]></dc:creator>
				<category><![CDATA[Aprendizado de Máquina]]></category>
		<category><![CDATA[Data Mining]]></category>
		<category><![CDATA[Educação]]></category>
		<category><![CDATA[Estatística]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Mineração de Dados]]></category>
		<category><![CDATA[Preparação de Dados]]></category>
		<category><![CDATA[R e RStudio]]></category>

		<guid isPermaLink="false">./../../../index.html?p=851</guid>
		<description><![CDATA[Na Parte 1 desse post (que já publiquei faz um tempão!) eu fiz uma classificação de imagens de dígitos escritos a mão usando o k-nn (algoritmo dos vizinhos mais próximos) usando as informações das imagens sem nenhum tipo de tratamento, isto é, sem nenhum método de preparação. Como foi mostrado, o k-nn só foi capaz de classificar razoavelmente bem com com k = 1 e conseguiu uma acurácia de apenas 78%, algo muito distante do que...]]></description>
				<content:encoded><![CDATA[<p style="text-align: justify;">Na <a href="./../../../2014/12/22/reconhecimento-de-digitos-escritos-mao-parte-1/index.html">Parte 1</a> desse post (que já publiquei faz um tempão!) eu fiz uma classificação de imagens de dígitos escritos a mão usando o <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">k-nn</a> (algoritmo dos vizinhos mais próximos) usando as informações das imagens sem nenhum tipo de tratamento, isto é, sem nenhum método de preparação. Como foi mostrado, o <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">k-nn</a> só foi capaz de classificar razoavelmente bem com com k = 1 e conseguiu uma acurácia de apenas 78%, algo muito distante do que ainda pode ser conseguido.</p>
<p style="text-align: justify;">Na <a href="./../../../2015/09/14/reconhecimento-de-digitos-escritos-a-mao-parte-2/index.html">Parte 2</a> eu trabalhei com um método de redução de dimensionalidade, o PCA, e também foram explorados diversos outros classificadores, como o Random Forest, o SVM e etc. O resumo dos resultados foi o seguinte:</p>
<ul style="text-align: justify;">
<li style="text-align: justify;">k-nn com k = 1: 84%</li>
<li style="text-align: justify;">Regressão linear: 14%</li>
<li style="text-align: justify;">Regressão Logística Multinomial: 64%</li>
<li style="text-align: justify;">Árvores de decisão: 24%</li>
<li style="text-align: justify;">RandomForest: 72%</li>
</ul>
<p style="text-align: justify;">E a conclusão geral foi que não foi possível bater o k-NN ou ainda mais chegar aos resultados reportados na literatura, superiores a 95% de acurácia na tarefa. Como foi mencionado anteriormente, os possíveis problemas foram:</p>
<ol style="text-align: justify;">
<li>Conjunto pequeno de imagens.</li>
<li>Modelos com parâmetros default.</li>
</ol>
<p style="text-align: justify;">Assim, nessa última parte vou mostrar como é possível treinar melhores modelos com muito mais dados e como é possível melhorar a performance dos algoritmos com melhores hiperparâmetros. Outro ponto importante que eu queria mostrar também é o uso do pacote <a href="http://caret.r-forge.r-project.org/">caret</a> para automatizar diversas tarefas desse processo.</p>
<h2 style="text-align: justify;">1.Dados e visualização</h2>
<p style="text-align: justify;">Como eu comentei antes, vamos nessa parte tentar utilizar um conjunto maior de imagens. Para tanto, ao invés desse pequeno conjunto de teste e treino que foi fornecido na <a href="./../../../2014/12/22/reconhecimento-de-digitos-escritos-mao-parte-1/index.html">Parte 1</a>, vamos utilizar um conjunto muito maior de images de dígitos escritos a mão, o famoso data set <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>. Se você verificar nesse link, você vai encontrar diversas informações com respeito a esse conjunto de dados e também você pode baixa-lo e utilizar nas análises que se seguem, caso queira reproduzir o que você está vendo aqui. ENTRETANTO, para poupar o seu trabalho e o meu, ao invés de pegar os dados diretamente deste site, vamos utilizar esse mesmo conjunto de dados já tratado e preparado pela equipe do <a href="https://www.kaggle.com/c/digit-recognizer">Kaggle</a>. A vantagem é que o arquivos já estão no formato csv e não será mais necessária a etapa de preparação realizada na <a href="./../../../2014/12/22/reconhecimento-de-digitos-escritos-mao-parte-1/index.html">Parte 1</a> e na <a href="./../../../2015/09/14/reconhecimento-de-digitos-escritos-a-mao-parte-2/index.html">Parte 2</a> desta série. Outra vantagem é que após você rodar estes modelos, se você quiser, você pode submeter seus resultados no Leaderboard para experimentar como funciona esse site de competição.</p>
<p style="text-align: justify;">Na <a href="./../../../2015/09/14/reconhecimento-de-digitos-escritos-a-mao-parte-2/index.html">Parte 2</a>, como eu peguei diretamente as imagens e converti em uma matriz, agora você poderia ficar confuso e se perguntar: mas e aí, como são estas imagens? como eu vou ver se já está em csv? Para você não ficar com dúvida, vamos &#8220;imprimir&#8221; as imagens.</p>
<pre class="lang:r decode:true ">############ Explorando as imagens ###############################
## Contando o número de imagens por dígito
barplot(table(treino$label), ylim = c(0,5000))

## Transformando em uma matriz
treino &lt;- as.matrix(treino)

## Imprimindo uma imagem
matriz_imagem &lt;- matrix(treino[1000,-1], ncol = 28)
matriz_imagem &lt;- matriz_imagem[,28:1] ## invertendo a imagem
image(1:28, 1:28, matriz_imagem, col = c('white', 'black'))</pre>
<p><a href="./../../../wp-content/uploads/2016/03/digito4.png" rel="attachment wp-att-867"><img class="aligncenter size-full wp-image-867" src="./../../../wp-content/uploads/2016/03/digito4.png" alt="digito4" width="480" height="480" srcset="./../../../wp-content/uploads/2016/03/digito4.png 480w, ./../../../wp-content/uploads/2016/03/digito4-150x150.png 150w, ./../../../wp-content/uploads/2016/03/digito4-300x300.png 300w, ./../../../wp-content/uploads/2016/03/digito4-65x65.png 65w" sizes="(max-width: 480px) 100vw, 480px" /></a></p>
<p>Veja que eu peguei a primeira linha do conjunto de treino, transformei em uma matriz e imprimi a matriz como uma imagem. Nesse caso é o dígito 4. Assim, apesar de agora você estar usando um arquivo em csv preparado eles fizeram a mesma coisa que eu fiz anteriormente. Se você quiser entender melhor como cada imagem virou uma linha dessa tabela dá uma olhada na Parte 1 dessa série. Só para mostrar que os dígitos estão ok, eu vou imprimir uma &#8220;imagem média&#8221;, onde em cada imagem eu tenho um valor médio em cada píxel considerando todas as imagens do conjunto de dados.</p>
<pre class="lang:r decode:true ">## Plotando uma imagem média para cada dígito
## Definindo uma escala de cor, indo do branco ao preto
colors &lt;- c('white','black')
cus_col &lt;- colorRampPalette(colors=colors)

## Plot de cada imagem média
## Divindo a tela
png('todos_digitos.png')
par(mfrow=c(4,3),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')

## Criando um array para armazenar as matrizes de cada imagem média
all_img &lt;- array(dim=c(10,28*28))

## Recuperando todas as imagens por dígito e calculando a média
for(di in 0:9) {
  print(di)
  all_img[di+1,] &lt;- apply(treino[treino[,1]==di,-1],2,sum)
  all_img[di+1,] &lt;- all_img[di+1,]/max(all_img[di+1,])*255
  
  z&lt;-array(all_img[di+1,],dim=c(28,28))
  z&lt;-z[,28:1] ##right side up
  image(1:28,1:28,z,main=di,col=cus_col(256))
}</pre>
<p><a href="./../../../wp-content/uploads/2016/03/todos_digitos-1.png" rel="attachment wp-att-869"><img class="aligncenter size-full wp-image-869" src="./../../../wp-content/uploads/2016/03/todos_digitos-1.png" alt="todos_digitos" width="480" height="480" srcset="./../../../wp-content/uploads/2016/03/todos_digitos-1.png 480w, ./../../../wp-content/uploads/2016/03/todos_digitos-1-150x150.png 150w, ./../../../wp-content/uploads/2016/03/todos_digitos-1-300x300.png 300w, ./../../../wp-content/uploads/2016/03/todos_digitos-1-65x65.png 65w" sizes="(max-width: 480px) 100vw, 480px" /></a></p>
<p style="text-align: justify;">Até há uma certa variação (por isso que há uma sombra) mas no geral os mesmos píxels tem uma intensidade maior considerando cada dígito diferente que foi escrito na imagem. Isso nos leva a crer que os modelos devem conseguir distinguir um dígito do outro.</p>
<h2 style="text-align: justify;">2. Preparação com PCA</h2>
<p style="text-align: justify;">Depois que você baixar os arquivos train.csv e test.csv do Kaggle já podemos efetuar a leitura dos arquivos e a preparação por meio do PCA. O que vamos fazer é aplicar o PCA e retendo somente o número de componentes necessário para alcançar 95% da variância total. Os detalhes sobre isso eu discuti na Parte 2.</p>
<pre class="lang:r decode:true ">## Leitura dos conjuntos de dados de treino e de teste
treino = read.csv('train.csv', header = T)
teste = read.csv('test.csv', header = T)

############ APlicação do PCA ####################################
## Obtendo componentes principais
pc &lt;- prcomp(treino[,-1])
treino_pc &lt;- pc$x

## Obtendo as variâncias acumuladas
vars = pc$sdev^2
props = vars/sum(vars)
varAcum = cumsum(props)
which.min(varAcum &lt; 0.90)

## Aplicando a rotação nos dados de teste
teste_pc &lt;- predict(pc, newdata = teste)

## Salvando treino e teste com PCA
save(treino_pc, file = 'treino_pc.rda')
save(teste_pc, file = 'teste_pc.rda')</pre>
<p style="text-align: justify;">eu costumo salvar os arquivos após cada etapa de preparação de forma a não precisar realizar o processo posteriormente. Outro ponto importante é que salvando os objetos no formato nativo do R, caso você precise recarregar os dados, o processo é muito mais rápido que a leitura em csv.</p>
<h2 style="text-align: justify;">3. Árvore de Decisão</h2>
<p style="text-align: justify;">Como uma primeira tentativa, vamos utilizar o algoritmo para árvores de decisão do pacote <a href="https://cran.r-project.org/web/packages/rpart/index.html">rpart</a>. Vamos utilizar todas as PC&#8217;s e treinar a árvore em 3/4 dos dados. O teste será realizado no 1/4 que foi separado.</p>
<pre class="lang:r decode:true ">#################################################################
## Teste com árvore de decisão
library(rpart)

## Separando o conjunto treino em dois para avaliação
set.seed(1)
inTrain &lt;- createDataPartition(treino$label, p = 3/4, list = F)
train &lt;- treino_pc[inTrain,]
evaluation &lt;- treino_pc[-inTrain,]

## Data frame de treino e teste
treino_arvore = as.data.frame(cbind(train[,1:784]))
treino_arvore$classes = as.factor(treino$label[inTrain])

## Conjunto de teste para avaliação
teste_arvore = as.data.frame(evaluation[,1:784])

## Criando uma árvore
arvore &lt;- rpart(classes ~ ., data = treino_arvore)

## Calculando a matriz de confusão
confusionMatrix(predict(arvore, teste_arvore, type = 'class'), treino$label[-inTrain])
</pre>
<p>e o resultado da matriz de confusão:</p>
<pre class="lang:r decode:true ">Confusion Matrix and Statistics

          Reference
Prediction   0   1   2   3   4   5   6   7   8   9
         0 637   2  13  20   3  66  17  12   0   2
         1   0 995   9   7  28   7   3  75   6  53
         2  60  54 741  61  30  97 130  16  93  10
         3 185  45 111 803  13 270 106  29  89  30
         4   3   0  16  10 796  73  16  82  16 471
         5  86  13  46  88  36 341  31  61 185  49
         6  24  16  47  45  21  40 725   4  13  43
         7  17   0   4   2  20  16   2 652  10  85
         8  18  46  40  27  11  60  12  18 532  13
         9  14   0   6  10  74   6  13 103  57 305

Overall Statistics
                                         
               Accuracy : 0.6217         
                 95% CI : (0.6124, 0.631)
    No Information Rate : 0.1115         
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
                                         
                  Kappa : 0.5796         
 Mcnemar's Test P-Value : &lt; 2.2e-16</pre>
<p style="text-align: justify;">mostra que o desempenho ainda está longe do satisfatório. Com uma acurácia global de apenas 62% estamos ainda muito longe da meta de 95%. Veja que utilizamos a estratégia <a href="http://stats.stackexchange.com/questions/104713/hold-out-validation-vs-k-fold-validation">holdout</a>, e com relação a <a href="./../../../2015/09/14/reconhecimento-de-digitos-escritos-a-mao-parte-2/index.html">Parte 2</a> desta série a única mudança é o fato de estarmos trabalhando com imagens com mais resolução e um conjunto maior. Parece que isso ainda não é o suficiente, assim vamos explorar outros algoritmos e vamos utilizar métodos de validação cruzada para encontrar os melhores hiperparâmetros.</p>
<h2>4. RandomForest</h2>
<p style="text-align: justify;">O <a href="https://en.wikipedia.org/wiki/Random_forest">randomforest</a> é um dos algoritmos de machine learning <a href="https://www.quora.com/What-are-the-top-10-data-mining-or-machine-learning-algorithms">mais utilizados na indústria</a>. Seu sucesso advém do fato de ser robusto, facilmente paralelizável e apresentar um desempenho muito bom em uma grande quantidade de problemas diferentes. Assim, vamos experimentar esse classificador procurando ajustar os melhores hiperperâmetros por validação cruzada. No caso do RF temos que definir qual o melhor m, um parâmetro que determina quantas variáveis são sorteadas na escolha do split em cada nó, de cada árvore de decisão do comitê. Se não ficou claro para você o que significa este hiperparâmetro não tem problema, não é difícil encontrar material onde você pode entender os detalhes do RF. O importante aqui é você entender que o valor do hiperparâmetro será escolhido com base no próprio conjunto de dados, utilizando validação cruzada.</p>
<pre class="lang:r decode:true">#################################################################
## Teste com RandomForest
library(randomForest)

## Separando o conjunto treino em dois para avaliação
set.seed(1)
inTrain &lt;- createDataPartition(treino$label, p = 3/4, list = F)
train &lt;- treino_pc[inTrain,]
evaluation &lt;- treino_pc[-inTrain,]

## Data frame de treino e teste, aqui retendo somente 160 PC's, equivalente a 95% de ## variância.
treino_arvore = as.data.frame(cbind(train[,1:160]))
treino_arvore$classes = as.factor(treino$label[inTrain])

## Conjunto de teste para avaliação
teste_arvore = as.data.frame(evaluation[,1:160])

## Modelagem
fitControl &lt;- trainControl(method = "oob", verboseIter = T,
                           
                           ## Estimate class probabilities
                           classProbs = F)

set.seed(825)
rfFit &lt;- train(classes ~ ., data = treino_arvore, verbose = T,
                method = "rf",
                trControl = fitControl,
                tuneLength = 8,
                metric = "Accuracy")
save(rfFit, file = 'rfFit.rda')
                
## Calculando a matriz de confusão
confusionMatrix(predict(rfFit, teste_arvore, type = 'raw'), treino$label[-inTrain])
</pre>
<p>e a matriz de confusão:</p>
<pre class="lang:r decode:true ">Confusion Matrix and Statistics

          Reference
Prediction    0    1    2    3    4    5    6    7    8    9
         0 1048    0    3    0    1    1    1    0    0    1
         1    0 1130    2    0    1    1    0    2    3    0
         2    0    3 1021   10    4    2    1    6    2    0
         3    0    1    5 1073    3   12    0    1    8   11
         4    1    0    6    0  970    4    1    1    4   18
         5    0    0    0    8    2  932    6    0    4    6
         6    6    1    3    2    5    3 1023    1    2    0
         7    1    1    4    4    0    0    0 1077    3    7
         8    0    0    5    4    5    2    1    2  967    4
         9    2    2    3    2   11    2    0    1    2 1020

Overall Statistics
                                          
               Accuracy : 0.9774          
                 95% CI : (0.9744, 0.9802)
    No Information Rate : 0.1084          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.9749</pre>
<p>e enfim chegamos a 97%!</p>
<h2 style="text-align: justify;">5. SVM (Máquina de vertores de suporte)</h2>
<p style="text-align: justify;">O SVM é um algoritmo do tipo &#8220;caixa preta&#8221;. O princípio por detrás do algoritmo é criar hiperplanos separadores em dimensões maiores do que as presentes no conjunto de dados. A ideia é que se os pontos são linearmente separáveis, isto é, se um hiperplano como fronteira de decisão conseguiria separar completamente as classes, então o SVM é um método que pode ser utilizado para encontrar esse hiperplano. ENTRETANTO, ocorre que muitos problemas não são linearmente separáveis, e ainda que fossem não valeria a pena usar o SVM. Quando o problema não é linearmente separável o SVM, de uma certa forma, projeta os dados em um espaço onde é possível criar um hiperplano separador. Também, ele aceita um certo grau de &#8220;impurezas&#8221; dentro das fronteiras de decisão. Enfim, é um algoritmo do tipo &#8220;caixa preta&#8221;, que não tem origem na estatística já que é basicamente um algoritmo de otimização. Mas o fato é que o SVM apresenta resultados muito bons e uma grande quantidade de problemas e vamos ver isso aqui nesse teste.</p>
<pre class="lang:r decode:true">#################################################################
## Teste com SVM RBF
## Carregando os pacotes
library(caret)

## Modelagem
fitControl &lt;- trainControl(method = "cv", verboseIter = T,
                           
                           ## Estimate class probabilities
                           classProbs = F)

set.seed(825)
svmFit &lt;- train(classes ~ ., data = treino_arvore,
                method = "svmRadial",
                trControl = fitControl,
                preProc = c("center", "scale"),
                tuneLength = 8,
                metric = "Accuracy")
save(svmFit, file = 'svmFit2.rda')

## Calculando a matriz de confusão
confusionMatrix(predict(svmFit, teste_arvore, type = 'raw'), treino$label[-inTrain])
</pre>
<p>e avaliando no conjunto de avaliação:</p>
<pre class="lang:r decode:true ">Confusion Matrix and Statistics

          Reference
Prediction    0    1    2    3    4    5    6    7    8    9
         0 1046    0    3    0    1    3    5    1    3    6
         1    1 1128    1    2    2    0    1    3    2    1
         2    0    3 1015   13    4    3    1   15    4    1
         3    1    1    4 1058    0   13    0    1    7    9
         4    2    2   10    1  972    1    4   10    1   21
         5    0    1    2   12    0  924    7    0    3    5
         6    5    0    2    1    5   10 1010    0    4    0
         7    0    0    5    7    0    0    0 1051    0   13
         8    3    2    9    4    0    2    5    1  967    3
         9    0    1    1    5   18    3    0    9    4 1008

Overall Statistics
                                          
               Accuracy : 0.9696          
                 95% CI : (0.9661, 0.9728)
    No Information Rate : 0.1084          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.9662</pre>
<p>e novamente conseguimos algo em torno de 97%. Para ser honesto, depois que eu criei os modelos com os melhores hiperparâmetros, submetendo no Kaggle o SVM supera os 98%. Foi o modelo com melhor desempenho nessa tarefa.</p>
<h2>Conclusão</h2>
<p style="text-align: justify;">Acho que depois da Parte 1, Parte 2 e Parte 3 (esta aqui!) você viu como se trabalha com classificação de imagens, como se prepara esse tipo de dado e como é possível alcançar altíssima acurácia utilizando os modelos de machine learning que você encontra por aí. Se você for reproduzir os exemplos, fique ciente que a etapa de modelagem pode demorar muito. No meu caso alguns destes modelos demoraram mais de 8 horas para o ajuste com os melhore hiperparâmetros! Outro ponto que eu não abordei é como o caret seleciona os melhores hiperparâmetros por validação cruzada. Isso vou deixar para falar com maior detalhe em outra oportunidade. Também gostaria de salientar que uma modelagem como essa é algo tipicamente diferente do que se espera em uma análise estatística tradicional. Aqui não estávamos interessados em inferência, mas sim em produzir modelos com o maior poder preditivo possível. Em casos como esse, trabalhar com métodos &#8220;caixa preta&#8221; não é em si um problema. O ponto principal é ter certeza que seu modelo apresentará um bom desempenho no futuro, com novos dados. POR FIM, esses modelos não são o estado da arte nesta tarefa, já que com <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> é possível passar dos 99% de acurácia.</p>
]]></content:encoded>
			<wfw:commentRss>./../../../2016/03/14/reconhecimento-de-digitos-escritos-mao-parte-3/feed/index.html</wfw:commentRss>
		<slash:comments>1</slash:comments>
		</item>
		<item>
		<title>Reconhecimento de dígitos escritos a mão – PARTE 2</title>
		<link>./../../../2015/09/14/reconhecimento-de-digitos-escritos-a-mao-parte-2/index.html</link>
		<comments>./../../../2015/09/14/reconhecimento-de-digitos-escritos-a-mao-parte-2/index.html#comments</comments>
		<pubDate>Mon, 14 Sep 2015 12:00:02 +0000</pubDate>
		<dc:creator><![CDATA[Flavio Barros]]></dc:creator>
				<category><![CDATA[Aprendizado de Máquina]]></category>
		<category><![CDATA[Estatística]]></category>
		<category><![CDATA[Mineração de Dados]]></category>
		<category><![CDATA[Preparação de Dados]]></category>
		<category><![CDATA[R e RStudio]]></category>

		<guid isPermaLink="false">http://www.flaviobarros.net/?p=746</guid>
		<description><![CDATA[Na Parte 1 desse post (que já publiquei faz um tempão!) eu fiz uma classificação de imagens de dígitos escritos mão usando o k-nn (algoritmo dos vizinhos mais próximos) usando as informações das imagens sem nenhum tipo de tratamento, isto é, sem nenhum método de preparação. Como foi mostrado, o k-nn só foi capaz de classificar razoavelmente bem com com k = 1 e conseguiu uma acurácia de apenas 78%, algo muito distante do que ainda...]]></description>
				<content:encoded><![CDATA[<p style="text-align: justify;">Na <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://www.flaviobarros.net/2014/12/22/reconhecimento-de-digitos-escritos-mao-parte-1/">Parte 1</a></span> desse post (que já publiquei faz um tempão!) eu fiz uma classificação de imagens de dígitos escritos mão usando o <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">k-nn</a> (algoritmo dos vizinhos mais próximos) usando as informações das imagens sem nenhum tipo de tratamento, isto é, sem nenhum método de preparação. Como foi mostrado, o <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">k-nn</a> só foi capaz de classificar razoavelmente bem com com k = 1 e conseguiu uma acurácia de apenas 78%, algo muito distante do que ainda pode ser conseguido.</p>
<p style="text-align: justify;">Assim, nesta segunda parte, vou explorar outras alternativas além do <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">k-nn</a>, e mais do que isso, tentar aplicar algum método de preparação para melhorar a performance dos algoritmos. Aqui vou repetir o procedimento de leitura do outro post, para facilitar a reprodução dessa análise.</p>
<p style="text-align: justify;">OBS: Leia a <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://www.flaviobarros.net/2014/12/22/reconhecimento-de-digitos-escritos-mao-parte-1/">Parte 1</a></span> para entender melhor o problema!</p>
<h3 style="text-align: justify;">1. LEITURA</h3>
<p style="text-align: justify;">Os dados do problema são imagens do tipo <a href="http://en.wikipedia.org/wiki/Netpbm_format"><span style="color: #0000ff;">PGM</span></a>, com 64 x 64 pixels por imagem, onde cada pixel tem valor 1 ou 0, indicando se o pixel é preto ou branco. Cada imagem tem um nome no formato X_ yyy.BMP.inv.pgm, onde o X representa o dígito desenhado na imagem. Os dados estão divididos em um conjunto de treino e um conjunto de teste e podem ser baixados nos seguintes links: <a href="http://www.flaviobarros.net/wp-content/uploads/2014/12/teste.zip">teste</a>  e <a href="http://www.flaviobarros.net/wp-content/uploads/2014/12/treino.zip">treino</a></p>
<p style="text-align: justify;">Assim a primeira parte do problema é efetuar a leitura dos dados. Para isso me utilizarei do pacote <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://cran.r-project.org/web/packages/pixmap/index.html">pixmap</a></span> com o qual é possível ler e manipular imagens PGM. A seguir, o processo de leitura das imagens e a criação de um vetor com as respostas, isto é, com o número do dígito que está escrito na imagem.</p>
<pre class="lang:r decode:true">## Carregando o pacote pixmap
library(pixmap)

## Definindo o diretório com as imagens de treino
path_treino &lt;- '/sua/pasta/treino/'

## Define como diretório de trabalho
setwd(path_treino)

## Lê os nomes dos arquivos
files &lt;- dir()

## Retira as classes dos nomes dos arquivos
classes &lt;- as.factor(substring(files,first=1,last=1))

## Cria data.frame para armazenar dados de treino
treino &lt;- as.data.frame(matrix(rep(0,length(files)*64*64), nrow=length(files)))

## Efetua leitura dos dados de treino
for (i in 1:length(files)) {

  ## Lendo as imagens
  x &lt;- read.pnm(files[i])

  ## No slot 'grey' está a matriz de pixels que é retirada e vetorizada
  treino[i,] &lt;- as.vector(x@grey, mode='integer')
}

## Define como diretório de trabalho o local das imagens para teste
path_teste &lt;- '/sua/pasta/teste/'

## Diretório de trabalho
setwd(path_teste)

## Lê os nomes dos arquivos
files &lt;- dir()

## Classes
predic &lt;- as.factor(substring(files,first=1,last=1))

## Cria data.frame para armazenar conjunto de teste
teste &lt;- as.data.frame(matrix(rep(0,length(files)*64*64), nrow=length(files)))

## Leitura do conjunto de teste
for (i in 1:length(files)) {
  x &lt;- read.pnm(files[i])
  teste[i,] &lt;- as.vector(x@grey, mode='integer')
}</pre>
<p style="text-align: justify;">É importante observar que a matriz de pixels fica armazenada no slot @grey, e que após a leitura é transformada em um vetor, tal que o data.frame final fica com 64&#215;64 colunas e 1949 linhas (o total de imagens). O conjunto de  teste tem somente 50 imagens, logo o data.frame vai ficar com 64&#215;64 colunas e somente 50 linhas. Em suma, cada coluna é um píxel e cada linha uma das diferentes imagens.</p>
<h2 style="text-align: justify;">Aplicação do PCA</h2>
<p style="text-align: justify;">O primeiro procedimento que vou utilizar aqui para tentar melhorar a performance da classificação, é usar o método de <span style="color: #0000ff;"><a style="color: #0000ff;" href="https://pt.wikipedia.org/wiki/An%C3%A1lise_de_Componentes_Principais">Análise de Componente Principais</a></span>, para fazer a rotação do sistema de coordenadas e então ficar somente com uma parte das componentes principais. No fim das contas, o que estaremos fazendo é uma redução do número de atributos pois preservando somente parte das componentes principais eu estarei reduzindo o número de colunas da matriz de dados.</p>
<p style="text-align: justify;">A ideia por trás desse procedimento é que nem todos os atributos (que nesse  caso são pixels) tem a mesma importância para entender o que está escrito na imagem. Pense que pixels que estão próximos da borda podem ter uma importância menor ao passo que pixels mais ao centro devem ser bem mais importantes. Veja que se tivéssemos 10 atributos (ou variáveis), digamos X1 X2 X3 &#8230; X10, então pela rotação do sistema obteríamos PC1 PC2 PC3 &#8230; PC10. A diferença é que as componentes principais, que serão utilizadas no lugar dos atributos originais, são ordenadas de acordo com a variância capturada, isto  é, a PC1 captura maior variância que a PC2 e assim por diante. Dessa forma poderemos escolher as primeiras que capturam a maior variância desejada, reduzindo assim o número de atributos que entram no modelo.</p>
<p style="text-align: justify;">Um detalhe importante da aplicação desse método é que após encontrar as componentes principais no conjunto de treino DEVEMOS APLICAR A MESMA ROTAÇÃO no conjunto de teste. Essa matriz de rotação DEVE SER A MESMA OBTIDA NO CONJUNTO DE TREINO, uma vez que eu não quero usar um método de redução de atributos que tenha utilizado qualquer informação do conjunto de testes. Isso é importante para garantir que a acurácia global inferida será o mais próximo possível do acurácia do modelo em novas imagens.</p>
<h3 style="text-align: justify;">PCA com prcomp</h3>
<p style="text-align: justify;">Para aplicar o PCA agora vou utilizar a função do pacote base <a href="https://stat.ethz.ch/R-manual/R-patched/library/stats/html/prcomp.html">prcomp</a>. Com ela vamos obter as componentes principais, no caso o mesmo número de colunas do conjunto de dados original, e também o desvio padrão de cada uma delas. Com essas duas informações poderemos avaliar a variância acumulada das componentes principais e escolher somente as primeiras que contemplem, vamos dizer, 90% da variância nesse conjunto de dados.</p>
<pre class="lang:r decode:true">############ APlicação do PCA ####################################
## Obtendo componentes principais
pc &lt;- prcomp(treino)
treino_x &lt;- pc$x

## Obtendo as variâncias acumuladas
vars = pc$sdev^2

## Calculando a proporção de variância 
props = vars/sum(vars)

## Obtendo as variâncias acumulada
varAcum = cumsum(props)

## Obtendo o número de componentes que capturam pelo menos 90% da variância.
which.min(varAcum &lt; 0.9)

## Aplicando a rotação nos dados de teste
test.p &lt;- predict(pc, newdata = teste)</pre>
<p style="text-align: justify;">Com 341 componentes principais capturamos 90% da variância. Isto é uma redução agressiva no número de atributos, uma vez que tínhamos mais de 1900 pixels. Agora estamos prontos para aplicar o método k-nn novamente, mas desta vez usando as 400 componentes principais como input (valor aproximado). Esperamos uma melhora.</p>
<h2 style="text-align: justify;">K-nn com PCA</h2>
<pre class="lang:r decode:true">## Treinando o knn com as 341 variáveis
predito &lt;- knn(train=pc$x[,1:400], test=test.p[,1:400], cl=classes, k=1, prob=T)

result &lt;- data.frame(cbind(predic, predito, acerto = predic==predito))

sum(result$acerto)/nrow(result)</pre>
<p style="text-align: justify;">Com k = 1 obtivemos uma performance de 84% de acurácia que já é uma melhora. Há que se notar também que não adianta muito colocar mais componentes e que também outros valores de k parecem não trazer grandes melhoras. Talvez seja a hora de partir para outros tipos de modelos a partir daqui. A seguir o gráfico do desempenho do k-nn ao longo dos valores de k com a inclusão de novas componentes.</p>
<p style="text-align: justify;"><a href="http://www.flaviobarros.net/wp-content/uploads/2015/09/valores_dim.png"><img class="aligncenter size-full wp-image-749" src="http://www.flaviobarros.net/wp-content/uploads/2015/09/valores_dim.png" alt="valores_dim" width="480" height="480" srcset="./../../../wp-content/uploads/2015/09/valores_dim.png 480w, ./../../../wp-content/uploads/2015/09/valores_dim-150x150.png 150w, ./../../../wp-content/uploads/2015/09/valores_dim-300x300.png 300w, ./../../../wp-content/uploads/2015/09/valores_dim-65x65.png 65w" sizes="(max-width: 480px) 100vw, 480px" /></a></p>
<h2 style="text-align: justify;">Árvore de decisão com PCA</h2>
<p style="text-align: justify;">Parece que não vamos muito mais longe com o k-nn, assim vamos tentar outros métodos como as árvores de decisão. Aqui vou usar a implementação do algoritmo <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">CART</a> no pacote <a href="https://cran.r-project.org/web/packages/rpart/index.html">rpart</a> do R. Vou usar como entrada as 400 componentes principais.</p>
<pre class="lang:r decode:true ">## Data frame de treino e teste
treino_arvore = as.data.frame(cbind(treino_pc[,1:544]))
treino_arvore$classes = classes

teste_arvore = as.data.frame(teste_pc[,1:544])

## Teste com árvore de decisão
library(rpart)

## Criando uma árvore
arvore &lt;- rpart(classes ~ ., data = treino_arvore)

## Fazendo a previsão no conjunto de teste
predito &lt;- predict(object = arvore, newdata = teste_arvore, type = 'class')

## Resultado
result &lt;- data.frame(cbind(predic, predito, acerto = predic==predito))

## Cálculo da taxa de acerto
sum(result$acerto)/nrow(result)</pre>
<p>O resultado foi inferior ao k-nn, com somente 72% de acurácia global.</p>
<p>A seguir vou apresentar ainda mais algumas tentativas com uma regressão linear, regressão logística multinomial e o randomForest.</p>
<h2>Outros modelos com PCA</h2>
<pre class="lang:r decode:true ">## Teste com logística multinomial
library(nnet)

## Ajustando um modelo
multinomial &lt;- multinom(classes ~ ., data = treino_arvore, MaxNWts = 5460)

## Fazendo a previsão no conjunto de teste
predito &lt;- predict(object = multinomial, newdata = teste_arvore, type = 'class')

## Resultado
result &lt;- data.frame(cbind(predic, predito, acerto = predic==predito))

## Cálculo da taxa de acerto
sum(result$acerto)/nrow(result)

#################################################################
## Teste com randomForest
library(randomForest)

## Ajustando um modelo
rf &lt;- randomForest(classes ~ ., data = treino_arvore)

## Fazendo a previsão no conjunto de teste
predito &lt;- predict(object = rf, newdata = teste_arvore, type = 'class')

## Resultado
result &lt;- data.frame(cbind(predic, predito, acerto = predic==predito))

## Cálculo da taxa de acerto
sum(result$acerto)/nrow(result)

#################################################################
## Teste com regressão linear
## Data frame de treino e teste
treino_arvore = as.data.frame(cbind(treino_pc[,1:544]))
treino_arvore$classes = classes

teste_arvore = as.data.frame(teste_pc[,1:544])

## Criando uma árvore
reg &lt;- lm(classes ~ ., data = treino_arvore)

## Fazendo a previsão no conjunto de teste
predito &lt;- predict(object = fit, newdata = teste_arvore)
predito &lt;- round(predito, 0)

## Resultado
result &lt;- data.frame(cbind(predic, predito, acerto = predic==predito))

## Cálculo da taxa de acerto
sum(result$acerto)/nrow(result)</pre>
<p>Com desempenhos inferiores ou iguais ao k-nn.</p>
<h2>Resumos dos resultados</h2>
<ul>
<li>k-nn com k = 1: 84%</li>
<li>Regressão Linear: 14%</li>
<li>Regressão Logística Multinomial: 64%</li>
<li>Árvore de Decisão: 34%</li>
<li>RandomForest: 72%</li>
</ul>
<h2>Conclusão</h2>
<p style="text-align: justify;">Por enquanto parece que não conseguimos passar do teto de 84% com o k-nn. Isso pode acontecer por diversos motivos, mas alguns possíveis responsáveis por ainda não alcançarmos os melhores resultados são:</p>
<ol style="text-align: justify;">
<li>No conjunto original teríamos mais de 60 mil imagens para treinar os algoritmos;</li>
<li>O conjunto de teste é muito pequeno logo há muita variabilidade na estimativa de erro;</li>
<li>Usamos parâmetros default em todos os modelos;</li>
</ol>
<p style="text-align: justify;">No próximo post vamos tentar encontrar os melhores hiperparâmetros para alguns modelos, tentar avaliar melhor o desempenho dos algoritmos, tentar novos algoritmos e automatizar tudo com o <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://caret.r-forge.r-project.org/">caret</a></span>.</p>
<p style="text-align: justify;">Gostou do artigo? Curta nossa página no Facebook!</p>
]]></content:encoded>
			<wfw:commentRss>./../../../2015/09/14/reconhecimento-de-digitos-escritos-a-mao-parte-2/feed/index.html</wfw:commentRss>
		<slash:comments>7</slash:comments>
		</item>
		<item>
		<title>Preparação de dados &#8211; Parte 2</title>
		<link>./../../../2015/09/07/preparacao-de-dados-parte-2/index.html</link>
		<comments>./../../../2015/09/07/preparacao-de-dados-parte-2/index.html#respond</comments>
		<pubDate>Mon, 07 Sep 2015 13:00:37 +0000</pubDate>
		<dc:creator><![CDATA[Flavio Barros]]></dc:creator>
				<category><![CDATA[Estatística]]></category>
		<category><![CDATA[Mineração de Dados]]></category>
		<category><![CDATA[Preparação de Dados]]></category>
		<category><![CDATA[R e RStudio]]></category>

		<guid isPermaLink="false">http://www.flaviobarros.net/?p=730</guid>
		<description><![CDATA[Neste post eu vou falar sobre como trabalhar com GRANDES ARQUIVOS DE TEXTO em chunks no R. Esse pode ser um problema complicado e que pode aparecer na vida do analista trabalhando com arquivos de log por exemplo. Antes de continuar o post gostaria de salientar que estou utilizando o termo chunk para designar um pedaço do arquivo de texto, isto é, estou dizendo que vamos trabalhar com grandes arquivos de texto, pedaço por pedaço. Mas por que...]]></description>
				<content:encoded><![CDATA[<p style="text-align: justify;">Neste post eu vou falar sobre como trabalhar com GRANDES ARQUIVOS DE TEXTO em <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://www.wordreference.com/enpt/chunk">chunks</a></span> no R. Esse pode ser um problema complicado e que pode aparecer na vida do analista trabalhando com <span style="color: #0000ff;"><a style="color: #0000ff;" href="https://en.wikipedia.org/wiki/Logfile">arquivos de log</a></span> por exemplo. Antes de continuar o post gostaria de salientar que estou utilizando o termo <em>chunk </em>para designar um pedaço do arquivo de texto, isto é, estou dizendo que vamos trabalhar com grandes arquivos de texto, pedaço por pedaço.</p>
<h2>Mas por que chunks?</h2>
<p style="text-align: justify;">Bom, se você já teve oportunidade de trabalhar com grandes arquivos de dados no R você já deve ter percebido que dependendo do tamanho do arquivo o simples procedimento de leitura pode demorar muito tempo. Isso ocorre porque o R trabalha com arquivos de dados diretamente na memória RAM tal que arquivos gigantescos ou podem ocupar toda a memória RAM do seu computador, inviabilizando a leitura, ou mesmo podem até ser lidos mas deixarem o computador extremamente lento tomando muito tempo da análise.</p>
<p style="text-align: justify;">Para mostrar um exemplo prático de como trabalhar com este tipo de arquivo no R vamos utilizar um conjunto de dados muito interessante com informações de vôos, o <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://stat-computing.org/dataexpo/2009/the-data.html">Airlines</a></span>. Vamos trabalhar somente com as informações relativas a 1988, mas que sozinhas já são suficiente para dar uma tremenda dor de cabeça. Para trabalhar com esses dados eu vou usar o pacote <span style="color: #0000ff;"><a style="color: #0000ff;" href="https://cran.r-project.org/web/packages/iterators/index.html">iterators</a></span>, um pacote que permite ler um arquivo linha por linha, ou chunk por chunk, mas sem ter que carregar o arquivo inteiro na memória. Para você ter uma ideia de como isso funciona tente rodar esse código:</p>
<pre class="lang:r decode:true">## Instalando e carregando o pacote
install.packages('iterators')
library(iterators)

## Efetuando a conexão de leitura do arquivo, direto do formato bz2 (uma espécie de zip).
con &lt;- bzfile('1988.csv.bz2', 'r')</pre>
<p style="text-align: justify;">Preste atenção que o objeto <strong>con</strong> armazena somente uma CONEXÃO. EU não estou lendo o arquivo ainda e portanto não o estou carregando na memória. Esse tipo de conexão é parecida com a que você poderia criar em um <span style="color: #0000ff;"><a style="color: #0000ff;" href="https://pt.wikipedia.org/wiki/Sistema_de_gerenciamento_de_banco_de_dados">sistema de gerenciamento de banco de dados</a></span> antes de fazer a primeira consulta em SQL.</p>
<p style="text-align: justify;">OK, agora que temos a conexão vamos criar um iterator (ou iterador):</p>
<pre class="lang:r decode:true">## Cria um iterador que lê uma linha do arquivo por vez (n = 1)
it &lt;- ireadLines(con, n=1)

## Comando para ir retornando linha a linha
nextElem(it)
nextElem(it)</pre>
<p style="text-align: justify;">Como você pode ver você está imprimindo no terminal linha por linha do arquivo. Assim, se você quiser trabalhar linha por linha, ou mesmo chunk por chunk (n &gt; 1) você pode ir carregando pequenos pedaços do arquivo que não vão ocupar a memória inteira.</p>
<h2 style="text-align: justify;">Mas como saber qual é a última linha?</h2>
<p style="text-align: justify;">Como estamos lendo linha a linha não temos como saber de antemão quantas linhas devemos ler. Assim a solução para o problema é tentar pegar o erro que ocorre quando chegamos na última linha do arquivo e pedimos mais uma com o nextElem(it). Quando fazemos isso a função retorna um erro, o qual podemos &#8220;transformar&#8221; em um FALSE do R e usar esse sinal em um programa para encerrar o trabalho.</p>
<pre class="lang:r decode:true">tryCatch(expr=nextElem(it), error=function(e) return(FALSE))</pre>
<p>esse comando retorna um  FALSE quando chega no fim do arquivo. Esse é um truque muito útil na preparação com grandes arquivos de texto.</p>
<h2>Exemplo do Stackoverflow</h2>
<p style="text-align: justify;">Há um tempo atrás surgiu uma pergunta no stackoverflow justamente sobre grandes arquivos de texto. Você encontrar a pergunta aqui: <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://pt.stackoverflow.com/questions/35469/pre-processar-grande-arquivo-de-texto-txt-substituir-por/35645#35645" target="_blank">Pre-processar grande arquivo de texto</a></span>. Veja que há também uma solução interessante do Carlos Cinelli (do <a href="http://analisereal.com/" target="_blank">analisereal.com</a>) que não faz uso do iterators. É uma solução que usa o seguinte método: lê 4000 linhas por vez e pula as linhas já lidas anteriormente. Eu acredito que a estratégia com iterators pode ser melhor pois você só vai varrer o arquivo uma vez, isto é, na solução com iterator você tem um apontador para a linha que parou e pode continuar a partir dali, até chegar no final do arquivo. Na solução usando o read.csv() ou read.table() em cada iteração o arquivo é lido novamente e todas as linhas já lidas são puladas.</p>
<pre class="lang:r decode:true ">## Carregando o pacote
library(iterators)

## Defindo a função que troca vírgula por ponto
change_dot &lt;- function(file, saida='teste.txt', chunk=1) {

  ## Cria conexão com arquivo a ser lido
  con1 &lt;- file(file, 'r')

  ## Cria conexão onde será escrito o novo arquivo
  con2 &lt;- file(saida, open = 'w')
  linha &lt;- 0

  ## Criando o iterador
  it &lt;- ireadLines(con1, n=chunk)

  ## Lendo a primeira linha e escrevendo no outro arquivo
  out &lt;- tryCatch(expr=write(x = gsub(pattern = ',', replacement = '.', x = nextElem(it)), con2), 
                   error=function(e) e)

  ## Observe o uso do tryCatch() para saber o fim do arquivo
  while(!any(class(out) == "error")) {
    linha = linha + 1
    print(paste('Escrita linha ', linha))
    out &lt;- tryCatch(expr=write(x = gsub(pattern = ',', replacement = '.', x = nextElem(it)), con2, append = T), 
                  error=function(e) e)
  }
}</pre>
<p>Nesse caso em específico o tempo total para a realização da tarefa foi de aproximadamente 6 segundos.</p>
<p>Gostou do artigo ou achou a dica útil?! Curta nossa página no Facebook!</p>
]]></content:encoded>
			<wfw:commentRss>./../../../2015/09/07/preparacao-de-dados-parte-2/feed/index.html</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Reconhecimento de dígitos escritos a mão &#8211; Parte 1</title>
		<link>./../../../2014/12/22/reconhecimento-de-digitos-escritos-mao-parte-1/index.html</link>
		<comments>./../../../2014/12/22/reconhecimento-de-digitos-escritos-mao-parte-1/index.html#comments</comments>
		<pubDate>Mon, 22 Dec 2014 18:58:00 +0000</pubDate>
		<dc:creator><![CDATA[Flavio Barros]]></dc:creator>
				<category><![CDATA[Aprendizado de Máquina]]></category>
		<category><![CDATA[Estatística]]></category>
		<category><![CDATA[Mineração de Dados]]></category>
		<category><![CDATA[Preparação de Dados]]></category>
		<category><![CDATA[R e RStudio]]></category>
		<category><![CDATA[k-nn]]></category>
		<category><![CDATA[mnist]]></category>

		<guid isPermaLink="false">http://www.flaviobarros.net/?p=493</guid>
		<description><![CDATA[A tarefa de reconhecimento de dígitos escritos a mão foi um dos primeiro grandes sucessos dos métodos de aprendizado de máquina. Hoje em dia, a tarefa pode ser realizada por diversas bibliotecas especializadas com altíssima acurácia (&#62; 97% de acertos), tal que muitas vezes, apesar de utilizarmos indiretamente esses recursos em tablets e smartphones, em geral não sabemos exatamente como o método funciona. Pensando nisso, como já trabalhei com esse problema antes, vou demonstrar nesse post...]]></description>
				<content:encoded><![CDATA[<p style="text-align: justify;">A tarefa de reconhecimento de dígitos escritos a mão foi um dos primeiro <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://en.wikipedia.org/wiki/Handwriting_recognition">grandes sucessos</a></span> dos métodos de aprendizado de máquina. Hoje em dia, a tarefa pode ser realizada por diversas <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://opencv.org/">bibliotecas especializadas</a> </span>com altíssima acurácia (&gt; 97% de acertos), tal que muitas vezes, apesar de utilizarmos indiretamente esses recursos em tablets e smartphones, em geral não sabemos exatamente como o método funciona.</p>
<p style="text-align: justify;"><a href="./../../../wp-content/uploads/2014/12/3_032.BMP.png" rel="attachment wp-att-506"><img class="aligncenter size-full wp-image-506" src="./../../../wp-content/uploads/2014/12/3_032.BMP.png" alt="3_032.BMP" width="64" height="64" /></a></p>
<p style="text-align: justify;">Pensando nisso, como já trabalhei com esse problema antes, vou demonstrar nesse post como o processo funciona, as técnicas utilizadas e como implementar tudo na linguagem R. Para começar, vamos trabalhar com o problema de reconhecer se o dígito é 0,1,2,3,4,5,6,7,8,ou 9, isto é, um problema de classificação com 10 categorias.</p>
<p style="text-align: justify;">Vou tentar trabalhar aqui implementando toda a modelagem somente com as funções do pacote base e uns poucos pacotes extras com as funções e algoritmos necessários; em um próximo post, posso tentar utilizar outros pacotes para automatizar as diversas etapas da modelagem.</p>
<p style="text-align: justify;"><span id="more-493"></span></p>
<h3 style="text-align: justify;">1. LEITURA</h3>
<p style="text-align: justify;">Os dados do problema são imagens do tipo <a href="http://en.wikipedia.org/wiki/Netpbm_format"><span style="color: #0000ff;">PGM</span></a>, com 64 x 64 pixels por imagem, onde cada pixel tem valor 1 ou 0, indicando se o pixel é preto ou branco. Cada imagem tem um nome no formato X_ yyy.BMP.inv.pgm, onde o X representa o dígito desenhado na imagem. Os dados estão divididos em um conjunto de treino e um conjunto de teste e podem ser baixados nos seguintes links: <a href="./../../../wp-content/uploads/2016/03/teste.zip">teste</a>  e <a href="./../../../wp-content/uploads/2016/03/treino.zip">treino</a></p>
<p style="text-align: justify;">Assim a primeira parte do problema é efetuar a leitura dos dados. Para isso me utilizarei do pacote <span style="color: #0000ff;"><a style="color: #0000ff;" href="http://cran.r-project.org/web/packages/pixmap/index.html">pixmap</a></span> com o qual é possível ler e manipular imagens PGM. A seguir, o processo de leitura das imagens e a criação de um vetor com as respostas, isto é, com o número do dígito que está escrito na imagem.</p>
<pre class="lang:r decode:true">## Carregando o pacote pixmap
library(pixmap)

## Definindo o diretório com as imagens de treino
path_treino &lt;- '/sua/pasta/treino/'

## Define como diretório de trabalho
setwd(path_treino)

## Lê os nomes dos arquivos
files &lt;- dir()

## Retira as classes dos nomes dos arquivos
classes &lt;- as.factor(substring(files,first=1,last=1))

## Cria data.frame para armazenar dados de treino
treino &lt;- as.data.frame(matrix(rep(0,length(files)*64*64), nrow=length(files)))

## Efetua leitura dos dados de treino
for (i in 1:length(files)) {

  ## Lendo as imagens
  x &lt;- read.pnm(files[i])

  ## No slot 'grey' está a matriz de pixels que é retirada e vetorizada
  treino[i,] &lt;- as.vector(x@grey, mode='integer')
}

## Define como diretório de trabalho o local das imagens para teste
path_teste &lt;- '/sua/pasta/teste/'

## Diretório de trabalho
setwd(path_teste)

## Lê os nomes dos arquivos
files &lt;- dir()

## Classes
predic &lt;- as.factor(substring(files,first=1,last=1))

## Cria data.frame para armazenar conjunto de teste
teste &lt;- as.data.frame(matrix(rep(0,length(files)*64*64), nrow=length(files)))

## Leitura do conjunto de teste
for (i in 1:length(files)) {
  x &lt;- read.pnm(files[i])
  teste[i,] &lt;- as.vector(x@grey, mode='integer')
}</pre>
<p style="text-align: justify;">É importante observar que a matriz de pixels fica armazenada no slot @grey, e que após a leitura é transformada em um vetor, tal que o data.frame final fica com 64&#215;64 colunas e 1949 linhas (o total de imagens). O conjunto de  teste tem somente 50 imagens, logo o data.frame vai ficar com 64&#215;64 colunas e somente 50 linhas. Em suma, cada coluna é um píxel e cada linha uma das diferentes imagens.</p>
<h3> 2. MODELAGEM COM k-nn</h3>
<p style="text-align: justify;">Nessa etapa será realizado o aprendizado com o algoritmo k-nn (vizinhos mais próximos) sem nenhum tratamento dos dados. O algoritmo funciona atribuindo as classes às imagens, utilizando os valores conhecidos dos vizinhos mais próximos. Assim, digamos que k=3, o algoritmo busca as três imagens mais próximas, verifica qual é a classe majoritária dessas imagens e atribui essa classe à imagem sem label. É importante escolher um k ímpar para não ocorrer empates, por exemplo 2 vizinhos de uma classe e 2 de outra no caso de k=4.</p>
<pre class="lang:r decode:true">## Carrega pacote class com o k-nn
library(class)

## Utilizando o k-nn para previsão do dígitos nas imagens de teste
predito &lt;- knn(train=treino, test=teste, cl=classes, k=3, prob=T)

## Resultado
result &lt;- data.frame(cbind(predic, predito, acerto = predic==predito))

## Cálculo da taxa de acerto
sum(result$acerto)/nrow(result)

[1] 0.56</pre>
<p>E com um k=3 obtivemos uma taxa de acerto de somente 56%, muito aquém do que pode ser obtido. Assim, vamos rodar o algoritmo com diversos valores de k e verificar se conseguimos obter um resultado um pouco melhor.</p>
<pre class="lang:r decode:true">## Data.frame com todos os resultados
resultado &lt;- data.frame(k = rep(0,101), taxa=rep(0.00,101))

for (i in seq(from=1, to=101, by=2)) {
  
  ## Imprime o valor de k para controle
  print(i)
  
  ## Obtém os valores preditos para as imagens
  predito &lt;- knn(train=treino, test=teste, cl=classes, k=i, prob=T)
  
  ## Salva em um data.frame
  result &lt;- data.frame(cbind(predic, predito, acerto = predic==predito))
  
  ## Calcula a taxa de acerto e armazena no data.frame
  resultado[i,] &lt;- c(i,sum(result$acerto)/nrow(result))
}

## Elimina linhas com 0
resultado &lt;- subset(resultado, subset=resultado$taxa!=0)

## Plota o resultado para todos os k's
plot(resultado$taxa~resultado$k, main='Taxa de Acerto para o k-nn', xlab='Valores de K', ylab='Taxa de acerto')</pre>
<p>Obtendo o seguinte resultado:</p>
<p><a href="http://www.flaviobarros.net/wp-content/uploads/2014/12/valores_k.png"><img class="aligncenter size-full wp-image-502" src="http://www.flaviobarros.net/wp-content/uploads/2014/12/valores_k.png" alt="valores_k" width="480" height="480" srcset="./../../../wp-content/uploads/2014/12/valores_k.png 480w, ./../../../wp-content/uploads/2014/12/valores_k-150x150.png 150w, ./../../../wp-content/uploads/2014/12/valores_k-300x300.png 300w, ./../../../wp-content/uploads/2014/12/valores_k-90x90.png 90w, ./../../../wp-content/uploads/2014/12/valores_k-130x130.png 130w" sizes="(max-width: 480px) 100vw, 480px" /></a></p>
<p style="text-align: justify;">Vejam que obtivemos algo em torno de 78% com k=1, mas que ainda é um resultado muito ruim perto do que pode ser alcançado. Também vale notar que aumentar o k não ajuda muito no fim das contas, mas é importante ficar atento pois um k muito pequeno pode levar ao superajustamento ou overfitting.</p>
<h3>CONCLUSÃO PARCIAL</h3>
<p style="text-align: justify;"> Ao que tudo indica a classificação de imagens funciona bem utilizando um algoritmo simples, sem nenhum tipo de tratamento. ENTRETANTO, é possível fazer muito melhor. Na Parte 2 vamos automatizar algumas tarefas com pacote <a href="http://caret.r-forge.r-project.org/"><span style="color: #0000ff;">caret</span></a> e também vamos explorar outros algoritmos melhores como o <a href="http://en.wikipedia.org/wiki/Support_vector_machine"><span style="color: #0000ff;">SVM</span></a> e o <a href="http://en.wikipedia.org/wiki/Random_forest"><span style="color: #0000ff;">RandomForest</span></a>.</p>
]]></content:encoded>
			<wfw:commentRss>./../../../2014/12/22/reconhecimento-de-digitos-escritos-mao-parte-1/feed/index.html</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
	</channel>
</rss>
